{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from data_utils import * \n",
    "cv2.setNumThreads(0)\n",
    "cv2.ocl.setUseOpenCL(False)\n",
    "import albumentations as A\n",
    "\n",
    "\n",
    "class BaseDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        image_mask_dict = {}\n",
    "        self.data = []\n",
    "\n",
    "    def __len__(self):\n",
    "        # We adjust the ratio of different dataset by setting the length.\n",
    "        pass\n",
    "\n",
    "    \n",
    "    def aug_data_back(self, image):\n",
    "        transform = A.Compose([\n",
    "            A.ColorJitter(p=0.5, brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5),\n",
    "            A.ChannelShuffle()\n",
    "            ])\n",
    "        transformed = transform(image=image.astype(np.uint8))\n",
    "        transformed_image = transformed[\"image\"]\n",
    "        return transformed_image\n",
    "    \n",
    "    def aug_data_mask(self, image, mask):\n",
    "        transform = A.Compose([\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.RandomBrightnessContrast(p=0.5),\n",
    "            #A.Rotate(limit=20, border_mode=cv2.BORDER_CONSTANT,  value=(0,0,0)),\n",
    "            ])\n",
    "\n",
    "        transformed = transform(image=image.astype(np.uint8), mask = mask)\n",
    "        transformed_image = transformed[\"image\"]\n",
    "        transformed_mask = transformed[\"mask\"]\n",
    "        return transformed_image, transformed_mask\n",
    "\n",
    "\n",
    "    def check_region_size(self, image, yyxx, ratio, mode = 'max'):\n",
    "        pass_flag = True\n",
    "        H,W = image.shape[0], image.shape[1]\n",
    "        H,W = H * ratio, W * ratio\n",
    "        y1,y2,x1,x2 = yyxx\n",
    "        h,w = y2-y1,x2-x1\n",
    "        if mode == 'max':\n",
    "            if h > H or w > W:\n",
    "                pass_flag = False\n",
    "        elif mode == 'min':\n",
    "            if h < H or w < W:\n",
    "                pass_flag = False\n",
    "        return pass_flag\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        while(True):\n",
    "            try:\n",
    "                idx = np.random.randint(0, len(self.data)-1)\n",
    "                item = self.get_sample(idx)\n",
    "                print(\"Dataloading completed\")\n",
    "                return item\n",
    "            except Exception as e:\n",
    "                print(\"Error While Loading dataset\")\n",
    "                print(e)\n",
    "                idx = np.random.randint(0, len(self.data)-1)\n",
    "                \n",
    "    def get_sample(self, idx):\n",
    "        # Implemented for each specific dataset\n",
    "        pass\n",
    "\n",
    "    def sample_timestep(self, max_step =1000):\n",
    "        if np.random.rand() < 0.3:\n",
    "            step = np.random.randint(0,max_step)\n",
    "            return np.array([step])\n",
    "\n",
    "        if self.dynamic == 1:\n",
    "            # coarse videos\n",
    "            step_start = max_step // 2\n",
    "            step_end = max_step\n",
    "        elif self.dynamic == 0:\n",
    "            # static images\n",
    "            step_start = 0 \n",
    "            step_end = max_step // 2\n",
    "        else:\n",
    "            # fine multi-view images/videos/3Ds\n",
    "            step_start = 0\n",
    "            step_end = max_step\n",
    "        step = np.random.randint(step_start, step_end)\n",
    "        return np.array([step])\n",
    "\n",
    "    def check_mask_area(self, mask):\n",
    "        H,W = mask.shape[0], mask.shape[1]\n",
    "        mask = mask/255\n",
    "        ratio = mask.sum() / (H * W)\n",
    "        if ratio > 0.8 * 0.8  or ratio < 0.1 * 0.1:\n",
    "            return False\n",
    "        else:\n",
    "            return True \n",
    "    \n",
    "\n",
    "    def process_pairs_new(self, ref_image, ref_mask, tar_image, tar_mask, max_ratio = 0.8):\n",
    "        assert mask_score(ref_mask) > 0.90\n",
    "        assert self.check_mask_area(ref_mask) == True\n",
    "        assert self.check_mask_area(tar_mask)  == True\n",
    "\n",
    "        # ========= Reference ===========\n",
    "        '''\n",
    "        # similate the case that the mask for reference object is coarse. Seems useless :(\n",
    "\n",
    "        if np.random.uniform(0, 1) < 0.7: \n",
    "            ref_mask_clean = ref_mask.copy()\n",
    "            ref_mask_clean = np.stack([ref_mask_clean,ref_mask_clean,ref_mask_clean],-1)\n",
    "            ref_mask = perturb_mask(ref_mask, 0.6, 0.9)\n",
    "            \n",
    "            # select a fake bg to avoid the background leakage\n",
    "            fake_target = tar_image.copy()\n",
    "            h,w = ref_image.shape[0], ref_image.shape[1]\n",
    "            fake_targe = cv2.resize(fake_target, (w,h))\n",
    "            fake_back = np.fliplr(np.flipud(fake_target))\n",
    "            fake_back = self.aug_data_back(fake_back)\n",
    "            ref_image = ref_mask_clean * ref_image + (1-ref_mask_clean) * fake_back\n",
    "        '''\n",
    "\n",
    "        # Get the outline Box of the reference image\n",
    "        ref_box_yyxx = get_bbox_from_mask(ref_mask)\n",
    "        assert self.check_region_size(ref_mask, ref_box_yyxx, ratio = 0.10, mode = 'min') == True\n",
    "\n",
    "        # Filtering background for the reference image\n",
    "        ref_mask_3 = np.stack([ref_mask,ref_mask,ref_mask],-1)\n",
    "        masked_ref_image = ref_image * ref_mask_3 + np.ones_like(ref_image) * 255 * (1-ref_mask_3)\n",
    "\n",
    "        y1,y2,x1,x2 = ref_box_yyxx\n",
    "        masked_ref_image = masked_ref_image[y1:y2,x1:x2,:]\n",
    "        ref_mask = ref_mask[y1:y2,x1:x2]\n",
    "        ratio = np.random.randint(11, 15) / 10 \n",
    "        masked_ref_image, ref_mask = expand_image_mask(masked_ref_image, ref_mask, ratio=ratio)\n",
    "        ref_mask_3 = np.stack([ref_mask,ref_mask,ref_mask],-1)\n",
    "\n",
    "        # Padding reference image to square and resize to 224\n",
    "        masked_ref_image = pad_to_square(masked_ref_image, pad_value = 255, random = False)\n",
    "        masked_ref_image = cv2.resize(masked_ref_image.astype(np.uint8), (224,224) ).astype(np.uint8)\n",
    "\n",
    "        ref_mask_3 = pad_to_square(ref_mask_3, pad_value = 0, random = False)\n",
    "        ref_mask_3 = cv2.resize(ref_mask_3.astype(np.uint8), (224,224) ).astype(np.uint8)\n",
    "        ref_mask = ref_mask_3[:,:,0]\n",
    "\n",
    "        # Augmenting reference image\n",
    "        # masked_ref_image_aug = self.aug_data(masked_ref_image) \n",
    "        \n",
    "        # Getting for high-freqency map\n",
    "        masked_ref_image_compose, ref_mask_compose =  self.aug_data_mask(masked_ref_image, ref_mask) \n",
    "        masked_ref_image_aug = masked_ref_image_compose.copy()\n",
    "        cv2.imwrite('a_masked_ref_image_compose.png', masked_ref_image_compose)\n",
    "\n",
    "        ref_mask_3 = np.stack([ref_mask_compose,ref_mask_compose,ref_mask_compose],-1)\n",
    "        ref_image_collage = sobel(masked_ref_image_compose, ref_mask_compose/255)\n",
    "        \n",
    "\n",
    "        # ========= Training Target ===========\n",
    "        tar_box_yyxx = get_bbox_from_mask(tar_mask)\n",
    "        tar_box_yyxx = expand_bbox(tar_mask, tar_box_yyxx, ratio=[1.1,1.2]) #1.1  1.3\n",
    "        assert self.check_region_size(tar_mask, tar_box_yyxx, ratio = max_ratio, mode = 'max') == True\n",
    "        \n",
    "        # Cropping around the target object \n",
    "        tar_box_yyxx_crop =  expand_bbox(tar_image, tar_box_yyxx, ratio=[1.3, 3.0])   \n",
    "        tar_box_yyxx_crop = box2squre(tar_image, tar_box_yyxx_crop) # crop box\n",
    "        y1,y2,x1,x2 = tar_box_yyxx_crop\n",
    "        cropped_target_image = tar_image[y1:y2,x1:x2,:]\n",
    "        cropped_tar_mask = tar_mask[y1:y2,x1:x2]\n",
    "        tar_box_yyxx = box_in_box(tar_box_yyxx, tar_box_yyxx_crop)\n",
    "        y1,y2,x1,x2 = tar_box_yyxx\n",
    "\n",
    "        # Prepairing collage image\n",
    "        ref_image_collage = cv2.resize(ref_image_collage.astype(np.uint8), (x2-x1, y2-y1))\n",
    "        ref_mask_compose = cv2.resize(ref_mask_compose.astype(np.uint8), (x2-x1, y2-y1))\n",
    "        # ref_mask_compose = (ref_mask_compose > 128).astype(np.uint8)\n",
    "        _, ref_mask_compose_new = cv2.threshold(ref_mask_compose, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        collage = cropped_target_image.copy() \n",
    "        collage[y1:y2,x1:x2,:] = ref_image_collage\n",
    "\n",
    "        collage_mask = cropped_target_image.copy() * 0.0\n",
    "        collage_mask[y1:y2,x1:x2,:] = 255.0\n",
    "\n",
    "        if np.random.uniform(0, 1) < 0.7: \n",
    "            cropped_tar_mask = perturb_mask(cropped_tar_mask)\n",
    "            # collage_mask = np.stack([cropped_tar_mask,cropped_tar_mask,cropped_tar_mask],-1)\n",
    "\n",
    "        H1, W1 = collage.shape[0], collage.shape[1]\n",
    "        \n",
    "        cropped_target_image = pad_to_square(cropped_target_image, pad_value = 0, random = False).astype(np.uint8)\n",
    "        collage = pad_to_square(collage, pad_value = 0, random = False).astype(np.uint8)\n",
    "        collage_mask = pad_to_square(collage_mask, pad_value = 0, random = False).astype(np.uint8)\n",
    "        H2, W2 = collage.shape[0], collage.shape[1]\n",
    "        \n",
    "        cropped_target_image = cv2.resize(cropped_target_image.astype(np.uint8), (512,512)).astype(np.float32)\n",
    "        collage = cv2.resize(collage.astype(np.uint8), (512,512)).astype(np.float32)\n",
    "        collage_mask  = cv2.resize(collage_mask.astype(np.uint8), (512,512),  interpolation = cv2.INTER_NEAREST).astype(np.float32)\n",
    "        \n",
    "        cv2.imwrite('a_image.png', ref_image)\n",
    "        cv2.imwrite('a_ref.png', masked_ref_image_aug)\n",
    "        cv2.imwrite('a_cropped_target.png', cropped_target_image)\n",
    "        cv2.imwrite('a_hint.png', collage)\n",
    "\n",
    "        # Prepairing dataloader items\n",
    "        masked_ref_image_aug = masked_ref_image_aug  / 255 \n",
    "        cropped_target_image = cropped_target_image / 127.5 - 1.0\n",
    "        collage = collage / 127.5 - 1.0 \n",
    "        collage = np.concatenate([collage, collage_mask[:,:,:1]  ] , -1)\n",
    "\n",
    "        item = dict(\n",
    "                ref=masked_ref_image_aug.copy(), \n",
    "                jpg=cropped_target_image.copy(), \n",
    "                hint=collage.copy(), \n",
    "                extra_sizes=np.array([H1, W1, H2, W2]), \n",
    "                tar_box_yyxx_crop=np.array(tar_box_yyxx_crop) \n",
    "                ) \n",
    "        return item\n",
    "\n",
    "\n",
    "    def process_pairs(self, ref_image, ref_mask, tar_image, tar_mask, max_ratio = 0.8):\n",
    "        assert mask_score(ref_mask) > 0.90\n",
    "        assert self.check_mask_area(ref_mask) == True\n",
    "        assert self.check_mask_area(tar_mask)  == True\n",
    "\n",
    "        # ========= Reference ===========\n",
    "        '''\n",
    "        # similate the case that the mask for reference object is coarse. Seems useless :(\n",
    "\n",
    "        if np.random.uniform(0, 1) < 0.7: \n",
    "            ref_mask_clean = ref_mask.copy()\n",
    "            ref_mask_clean = np.stack([ref_mask_clean,ref_mask_clean,ref_mask_clean],-1)\n",
    "            ref_mask = perturb_mask(ref_mask, 0.6, 0.9)\n",
    "            \n",
    "            # select a fake bg to avoid the background leakage\n",
    "            fake_target = tar_image.copy()\n",
    "            h,w = ref_image.shape[0], ref_image.shape[1]\n",
    "            fake_targe = cv2.resize(fake_target, (w,h))\n",
    "            fake_back = np.fliplr(np.flipud(fake_target))\n",
    "            fake_back = self.aug_data_back(fake_back)\n",
    "            ref_image = ref_mask_clean * ref_image + (1-ref_mask_clean) * fake_back\n",
    "        '''\n",
    "\n",
    "        # Get the outline Box of the reference image\n",
    "        ref_box_yyxx = get_bbox_from_mask(ref_mask)\n",
    "        assert self.check_region_size(ref_mask, ref_box_yyxx, ratio = 0.10, mode = 'min') == True\n",
    "        \n",
    "        # Filtering background for the reference image\n",
    "        ref_mask_3 = np.stack([ref_mask,ref_mask,ref_mask],-1)\n",
    "        masked_ref_image = ref_image * ref_mask_3 + np.ones_like(ref_image) * 255 * (1-ref_mask_3)\n",
    "\n",
    "        y1,y2,x1,x2 = ref_box_yyxx\n",
    "        masked_ref_image = masked_ref_image[y1:y2,x1:x2,:]\n",
    "        ref_mask = ref_mask[y1:y2,x1:x2]\n",
    "\n",
    "        ratio = np.random.randint(11, 15) / 10 \n",
    "        masked_ref_image, ref_mask = expand_image_mask(masked_ref_image, ref_mask, ratio=ratio)\n",
    "        ref_mask_3 = np.stack([ref_mask,ref_mask,ref_mask],-1)\n",
    "\n",
    "        # Padding reference image to square and resize to 224\n",
    "        masked_ref_image = pad_to_square(masked_ref_image, pad_value = 255, random = False)\n",
    "        masked_ref_image = cv2.resize(masked_ref_image.astype(np.uint8), (224,224) ).astype(np.uint8)\n",
    "\n",
    "        ref_mask_3 = pad_to_square(ref_mask_3 * 255, pad_value = 0, random = False)\n",
    "        ref_mask_3 = cv2.resize(ref_mask_3.astype(np.uint8), (224,224) ).astype(np.uint8)\n",
    "        ref_mask = ref_mask_3[:,:,0]\n",
    "\n",
    "        # Augmenting reference image\n",
    "        #masked_ref_image_aug = self.aug_data(masked_ref_image) \n",
    "        \n",
    "        # Getting for high-freqency map\n",
    "        masked_ref_image_compose, ref_mask_compose =  self.aug_data_mask(masked_ref_image, ref_mask) \n",
    "        masked_ref_image_aug = masked_ref_image_compose.copy()\n",
    "\n",
    "        ref_mask_3 = np.stack([ref_mask_compose,ref_mask_compose,ref_mask_compose],-1)\n",
    "        ref_image_collage = sobel(masked_ref_image_compose, ref_mask_compose/255)\n",
    "        \n",
    "\n",
    "        # ========= Training Target ===========\n",
    "        tar_box_yyxx = get_bbox_from_mask(tar_mask)\n",
    "        tar_box_yyxx = expand_bbox(tar_mask, tar_box_yyxx, ratio=[1.1,1.2]) #1.1  1.3\n",
    "        assert self.check_region_size(tar_mask, tar_box_yyxx, ratio = max_ratio, mode = 'max') == True\n",
    "        \n",
    "        # Cropping around the target object \n",
    "        tar_box_yyxx_crop =  expand_bbox(tar_image, tar_box_yyxx, ratio=[1.3, 3.0])   \n",
    "        tar_box_yyxx_crop = box2squre(tar_image, tar_box_yyxx_crop) # crop box\n",
    "        y1,y2,x1,x2 = tar_box_yyxx_crop\n",
    "        cropped_target_image = tar_image[y1:y2,x1:x2,:]\n",
    "        cropped_tar_mask = tar_mask[y1:y2,x1:x2]\n",
    "        tar_box_yyxx = box_in_box(tar_box_yyxx, tar_box_yyxx_crop)\n",
    "        y1,y2,x1,x2 = tar_box_yyxx\n",
    "\n",
    "        # Prepairing collage image\n",
    "        ref_image_collage = cv2.resize(ref_image_collage.astype(np.uint8), (x2-x1, y2-y1))\n",
    "        ref_mask_compose = cv2.resize(ref_mask_compose.astype(np.uint8), (x2-x1, y2-y1))\n",
    "        ref_mask_compose = (ref_mask_compose > 128).astype(np.uint8)\n",
    "\n",
    "        collage = cropped_target_image.copy() \n",
    "        collage[y1:y2,x1:x2,:] = ref_image_collage\n",
    "\n",
    "        collage_mask = cropped_target_image.copy() * 0.0\n",
    "        collage_mask[y1:y2,x1:x2,:] = 1.0\n",
    "\n",
    "        if np.random.uniform(0, 1) < 0.7: \n",
    "            cropped_tar_mask = perturb_mask(cropped_tar_mask)\n",
    "            collage_mask = np.stack([cropped_tar_mask,cropped_tar_mask,cropped_tar_mask],-1)\n",
    "\n",
    "        H1, W1 = collage.shape[0], collage.shape[1]\n",
    "\n",
    "        cropped_target_image = pad_to_square(cropped_target_image, pad_value = 0, random = False).astype(np.uint8)\n",
    "        collage = pad_to_square(collage, pad_value = 0, random = False).astype(np.uint8)\n",
    "        collage_mask = pad_to_square(collage_mask, pad_value = 2, random = False).astype(np.uint8)\n",
    "        H2, W2 = collage.shape[0], collage.shape[1]\n",
    "\n",
    "        cropped_target_image = cv2.resize(cropped_target_image.astype(np.uint8), (512,512)).astype(np.float32)\n",
    "        collage = cv2.resize(collage.astype(np.uint8), (512,512)).astype(np.float32)\n",
    "        collage_mask  = cv2.resize(collage_mask.astype(np.uint8), (512,512),  interpolation = cv2.INTER_NEAREST).astype(np.float32)\n",
    "        collage_mask[collage_mask == 2] = -1\n",
    "\n",
    "        cv2.imwrite('_image.png', ref_image)\n",
    "        cv2.imwrite('_ref.png', masked_ref_image_aug)\n",
    "        cv2.imwrite('_cropped_target.png', cropped_target_image)\n",
    "        cv2.imwrite('_hint.png', collage)\n",
    "\n",
    "        \n",
    "        # Prepairing dataloader items\n",
    "        masked_ref_image_aug = masked_ref_image_aug  / 255 \n",
    "        cropped_target_image = cropped_target_image / 127.5 - 1.0\n",
    "        collage = collage / 127.5 - 1.0 \n",
    "        collage = np.concatenate([collage, collage_mask[:,:,:1]  ] , -1)\n",
    "        \n",
    "        item = dict(\n",
    "                ref=masked_ref_image_aug.copy(), \n",
    "                jpg=cropped_target_image.copy(), \n",
    "                hint=collage.copy(), \n",
    "                extra_sizes=np.array([H1, W1, H2, W2]), \n",
    "                tar_box_yyxx_crop=np.array(tar_box_yyxx_crop) \n",
    "                ) \n",
    "        return item\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from data_utils import * \n",
    "from base import BaseDataset\n",
    "\n",
    "class MirrorsCounterfactualDataset(BaseDataset):\n",
    "    def __init__(self, data_dir):\n",
    "        self.images_dir = f\"{data_dir}/images\"\n",
    "        self.masks_dir = f\"{data_dir}/masks\"\n",
    "        self.def_dir = f\"{data_dir}/deformed\"\n",
    "\n",
    "        self.data = os.listdir(self.masks_dir)\n",
    "        self.size = (512, 640)\n",
    "        self.clip_size = (224,224)\n",
    "        self.dynamic = 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(os.listdir(self.masks_dir))\n",
    "\n",
    "    def check_region_size(self, image, yyxx, ratio, mode = 'max'):\n",
    "        pass_flag = True\n",
    "        H,W = image.shape[0], image.shape[1]\n",
    "        H,W = H * ratio, W * ratio\n",
    "        y1,y2,x1,x2 = yyxx\n",
    "        h,w = y2-y1,x2-x1\n",
    "        if mode == 'max':\n",
    "            if h > H and w > W:\n",
    "                pass_flag = False\n",
    "        elif mode == 'min':\n",
    "            if h < H and w < W:\n",
    "                pass_flag = False\n",
    "        return pass_flag\n",
    "\n",
    "\n",
    "    def get_sample(self, idx):\n",
    "        ref_mask_path = os.path.join(self.masks_dir, self.data[idx])\n",
    "        ref_image_path = os.path.join(self.def_dir, self.data[idx])\n",
    "        tar_image_path = os.path.join(self.images_dir, self.data[idx])\n",
    "        ref_mask = cv2.imread(ref_mask_path)\n",
    "        ref_mask = cv2.cvtColor(ref_mask, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        ref_image = cv2.imread(ref_image_path)\n",
    "        ref_image = cv2.cvtColor(ref_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        tar_image = cv2.imread(tar_image_path)\n",
    "        tar_image = cv2.cvtColor(tar_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # ref_mask = (ref_mask > 0).astype(np.uint8)\n",
    "        tar_mask = ref_mask.copy()\n",
    "        # cv2.imwrite('ref_mask0.png', ref_mask)\n",
    "\n",
    "        item_with_collage = self.process_pairs(ref_image, ref_mask, tar_image, tar_mask, max_ratio = 1.0)\n",
    "        sampled_time_steps = self.sample_timestep()\n",
    "        item_with_collage['time_steps'] = sampled_time_steps\n",
    "        item_with_collage['text'] = \"a perfect reflective planar mirror\"\n",
    "        return item_with_collage\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    dataset = MirrorsCounterfactualDataset(data_dir=\"/raid/ankit/om/dataset/MSD/test\")\n",
    "    k = dataset[123]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anydoor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
